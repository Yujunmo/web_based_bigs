{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea514cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 내용 읽기\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from langchain_community.document_loaders import Docx2txtLoader, TextLoader\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import tempfile\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "loader = UnstructuredLoader(\"./test_data/cash_flow.csv\")\n",
    "document = loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 쪼개기\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "      chunk_size=1500    #  token 수 \n",
    "    , chunk_overlap=200  #  겹치는 토큰 수 (중복되는 토큰이 많을수록 문맥 유지에 유리하지만, 중복되는 토큰이 많아질수록 저장공간이 늘어남)\n",
    "    )\n",
    "\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4151cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ele in document_list:\n",
    "    for col in ele.metadata.keys():\n",
    "        if isinstance(ele.metadata[col], list):\n",
    "            ele.metadata[col] = \", \".join(map(str, ele.metadata[col]))\n",
    "        else:\n",
    "            ele.metadata[col] = str(ele.metadata[col]) if not isinstance(ele.metadata[col], (str, int, float, bool)) else ele.metadata[col]            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9789b153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './test_data/cash_flow.csv',\n",
       " 'file_directory': './test_data',\n",
       " 'filename': 'cash_flow.csv',\n",
       " 'last_modified': '2025-10-06T23:28:11',\n",
       " 'page_name': 'Sheet2',\n",
       " 'page_number': 1,\n",
       " 'text_as_html': '<table><tr><td>운용사코드</td><td>펀드코드</td><td>펀드명</td><td>일자</td><td>현금흐름</td></tr><tr><td>03069</td><td>A0001</td><td>삼성코리아주식펀드</td><td>2020-01-01</td><td>-10000</td></tr><tr><td>03069</td><td>A0001</td><td>삼성코리아주식펀드</td><td>2020-07-01</td><td>-2000</td></tr><tr><td>03069</td><td>A0001</td><td>삼성코리아주식펀드</td><td>2021-03-01</td><td>5000</td></tr><tr><td>03069</td><td>A0001</td><td>삼성코리아주식펀드</td><td>2021-10-01</td><td>15000</td></tr><tr><td>03069</td><td>A0002</td><td>삼성글로벌반도체펀드</td><td>2022-06-30</td><td>-10000000</td></tr><tr><td>03069</td><td>A0002</td><td>삼성글로벌반도체펀드</td><td>2022-12-31</td><td>2000000</td></tr><tr><td>03069</td><td>A0002</td><td>삼성글로벌반도체펀드</td><td>2023-12-31</td><td>2500000</td></tr><tr><td>03069</td><td>A0002</td><td>삼성글로벌반도체펀드</td><td>2024-09-28</td><td>3000000</td></tr><tr><td>03069</td><td>A0002</td><td>삼성글로벌반도체펀드</td><td>2024-12-31</td><td>3500000</td></tr><tr><td>03069</td><td>A0002</td><td>삼성글로벌반도체펀드</td><td>2025-12-31</td><td>4000000</td></tr></table>',\n",
       " 'languages': 'kor',\n",
       " 'filetype': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n",
       " 'category': 'Table',\n",
       " 'element_id': '1a9c5952194bd21c76dd1d099a48bdee'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_list[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675d3fe",
   "metadata": {},
   "source": [
    "# 데이터 입력 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36a5bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83740b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel data 벡터화\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# embeddings = UpstageEmbeddings(model=\"embedding-query\")\n",
    "# database = Chroma(persist_directory='./public_db/' , collection_name='logic', embedding_function=embeddings)  # 기존에 생성한 벡터 DB를 불러옴\n",
    "# print(database._collection.count())\n",
    "\n",
    "# # data 확인 \n",
    "# data = database.get()\n",
    "# print(data['documents'][2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2647539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['documents'][0] == data['documents'][2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244774b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database._collection.count()\n",
    "database._collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddefceb3",
   "metadata": {},
   "source": [
    "# 유사도 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f132e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def get_embeddings(llm_type:str):\n",
    "\n",
    "    if llm_type == 'openai':\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    elif llm_type == 'upstage':\n",
    "        embeddings = UpstageEmbeddings(model=\"embedding-query\")\n",
    "    else:\n",
    "        st.error(\"지원하지 않는 LLM 타입입니다.\")\n",
    "        embeddings = None\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "embeddings = get_embeddings('upstage')    \n",
    "database = Chroma(persist_directory='./public_db' , embedding_function=embeddings, collection_name='menu')\n",
    "retrieved_docs = database.similarity_search('펀드별성과분석 화면', k=2)\n",
    "\n",
    "\n",
    "print(len(retrieved_docs))\n",
    "\n",
    "# for id,doc in enumerate(retrieved_docs):\n",
    "#     print('-'*100)\n",
    "#     print(f'{id}번째 문서')\n",
    "#     print(doc.page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f6d118a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 앱은 신한펀드파트너스라는 회사의 앱이야.\\n신한펀드파트너스는 한국의 일반사무관리회사야.\\n일반사무관리회사에 대한 설명은 아래와 같아.\\n일반사무관리회사는 한국거래소에 상장된 주식이나 채권 등 금융투자상품의 발행인으로부터 위탁받은 주식 사무 관련 업무를 수행하는 회사다.\\n즉, 투자자들이 원활하게 거래할 수 있도록 지원하는 것이 주 목적이다.\\n예를 들어 주주총회 소집 통지서 발송, 재무제표 승인 같은 중요한 의사 결정 시 필요한 서류 정리나 공시도 담당한다.\\n또한 증권사의 주문 내역 확인 후 이를 해당 종목의 매매 시스템에 입력하기도 한다.\\n이 외에도 명의개서 대행업무, 배당금 지급 준비 절차등 다양한 부수적인 일들을 함께 진행하며 단순히 문서작업 뿐 아니라 효율적이고 정확한 프로세스 관리가 필수적이다.\\n따라서 이러한 모든 활동들은 일정한 규정 내에서 이루어져야 하며 법적 문제가 발생하지 않도록 철저한 검토 과정도 거쳐야 한다.\\n이 앱은 신한펀드파트너스에 사무업무를 위탁한 고객사의 펀드들을 관리하는 것을 목적으로 하고 있어.\\n\\n\\n아래는 현재 앱에 있는 메뉴들의 정보입니다.\\n1. 내부수익률    : 펀드의 내부 수익률 또는 IRR을 계산해주는 화면. 펀드의 현금흐름을 계산하여 내부 수익률을 계산해주는 화면. \\n2. 펀드성과분석   : 펀드의 성과를 분석해주는 화면. 펀드의 수익률을 계산하여 펀드의 성과를 분석해주는 화면. 누적수익률, 초과수익률, BM 수익률 그래프를 그려주는 화면. \\n3. 주식보유현황   : 주식의 보유현황을 확인해주는 화면. 주식의 보유현황을 확인해주는 화면. \\n4. 채권보유현황   : 채권의 보유현황을 확인해주는 화면. 채권의 보유현황을 확인해주는 화면. \\n5. 종합보유현황   : 주식과 채권의 보유현황을 확인해주는 화면. 주식과 채권의 보유현황을 확인해주는 화면. \\n6. 주식거래내역 : 주식의 거래내역을 확인해주는 화면. 주식의 거래내역을 확인해주는 화면. \\n7. 그래프       : 그래프를 그려주는 화면. 그래프를 그려주는 화면. 운용사 직원이 보고서를 작성할 때 사용할 수 있는 다양한 그래프를 조회할 수 있는 화면. \\n8. 운용역정보   : 펀드 운용역의 정보를 확인해주는 화면. 운용역의 정보를 확인해주는 화면. 펀드매니저의 정보를 확인할 수 있는 화면.\\n9. 펀드기본정보 : 펀드의 기본정보를 확인해주는 화면. 펀드의 기본정보를 확인해주는 화면..1. 구성원 간 이익의 분배비율이 정하여져 있고 해당 구성원별로 이익의 분배비율이 확인되는 경우\\n\\n2. 구성원 간 이익의 분배비율이 정하여져 있지 아니하나 사실상 구성원별로 이익이 분배되는 것으로 확인되는 경우\\n\\n④ 제3항에도 불구하고 해당 단체의 전체 구성원 중 일부 구성원의 분배비율만 확인되거나 일부 구성원에게만 이익이 분배되는 것으로 확인되는 경우에는 다음 각 호의 구분에 따라 소득세 또는 법인세를 납부할 의무를 진다.<신설 2018. 12. 31.>\\n\\n1. 확인되는 부분: 해당 구성원별로 소득세 또는 법인세에 대한 납세의무 부담\\n\\n2. 확인되지 아니하는 부분: 해당 단체를 1거주자 또는 1비거주자로 보아 소득세에 대한 납세의무 부담\\n\\n⑤ 제3항 및 제4항에도 불구하고 법인으로 보는 단체 외의 법인 아닌 단체에 해당하는 국외투자기구(투자권유를 하여 모은 금전 등을 가지고 재산적 가치가 있는 투자대상자산을 취득, 처분하거나 그 밖의 방법으로 운용하고 그 결과를 투자자에게 배분하여 귀속시키는 투자행위를 하는 기구로서 국외에서 설립된 기구를 말한다. 이하 같다)를 제119조의2제1항제2호에 따라 국내원천소득의 실질귀속자로 보는 경우 그 국외투자기구는 1비거주자로서 소득세를 납부할 의무를 \\n\\n법제처\\n\\n\\n\\n2\\n\\n국가법령정보센터'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs ='.'.join([data.page_content for data in retrieved_docs]) \n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25195cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e8db569",
   "metadata": {},
   "source": [
    "# upstage basic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e416a363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a large language model, so I don't have feelings, but I'm here and ready to help you. How can I assist you today? 😊  \n",
      "\n",
      "Is there something specific you'd like to talk about or ask? Whether it's questions, creative writing, problem-solving, or just casual conversation—I'm here for it!  \n",
      "\n",
      "(And if you're feeling curious, I can share some fun facts or interesting tidbits too!)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI # openai==1.52.2\n",
    " \n",
    "client = OpenAI(\n",
    "    api_key=\"up_gxDYOP6oifTV8HSRaLoPJ3sUOixLE\",\n",
    "    base_url=\"https://api.upstage.ai/v1\"\n",
    ")\n",
    " \n",
    "stream = client.chat.completions.create(\n",
    "    model=\"solar-pro2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hi, how are you?\"\n",
    "        }\n",
    "    ],\n",
    "    stream=False,\n",
    ")\n",
    " \n",
    "# for chunk in stream:\n",
    "#     if chunk.choices[0].delta.content is not None:\n",
    "#         print(chunk.choices[0].delta.content, end=\"\")\n",
    " \n",
    "# Use with stream=False\n",
    "print(stream.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcd55ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am **Upstage's Solar Pro 2**, a large language model (LLM) developed by **Upstage**, a leading AI company founded in 2020. Here’s a quick overview of who I am:\n",
      "\n",
      "### 📌 **Key Features:**\n",
      "- **Model Size:** 30.9B parameters (Solar Pro 2 2025 version).\n",
      "- **Capabilities:**  \n",
      "  - **Thinking mode** (deep reasoning, complex tasks)  \n",
      "  - **Non-thinking mode** (fast, efficient responses)  \n",
      "  - Supports **Korean, Japanese, English**, and more.  \n",
      "  - Excels in **text generation, summarization, translation, coding**, and **structured document understanding (Document AI)**.\n",
      "\n",
      "### 🚀 **Powered by Upstage:**\n",
      "- **Technology:** Hybrid thinking modes, optimized for both performance and speed.  \n",
      "- **Document AI:** Specialized in **OCR, KIE (Key Information Extraction), and parsing structured documents**.  \n",
      "- **Solar API:** Offers **Chat, Structured Outputs, Translation, Summarization**, and **Code Generation** via APIs.  \n",
      "\n",
      "### 🌐 **Global Reach:**\n",
      "- Headquartered in **South Korea**, with offices in **Seoul, Tokyo, and Houston (Texas, U.S.)**.  \n",
      "- Partnered with **AWS** for cloud integration and global scalability.  \n",
      "\n",
      "Whether you need help with **research, writing, coding, or document processing**, I’m here to assist! 🚀  \n",
      "\n",
      "**How can I help you today?**\n"
     ]
    }
   ],
   "source": [
    " \n",
    "stream = client.chat.completions.create(\n",
    "    model=\"solar-pro2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"who are you?\"\n",
    "        }\n",
    "    ],\n",
    "    stream=False,\n",
    ")\n",
    " \n",
    "print(stream.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77436474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "import os\n",
    "from common.gpt_learning_data import *\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.passthrough import RunnablePassthrough\n",
    "from dotenv import load_dotenv\n",
    "from common.global_data import support_llm_type\n",
    "load_dotenv()\n",
    "\n",
    "def draw_chatbot(key:str):\n",
    "\n",
    "    option = st.radio(\"LLM 모델 선택\",support_llm_type , horizontal=True)\n",
    "\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "\n",
    "    # 채팅 기록 표시\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "\n",
    "    if query := st.chat_input(\"메시지를 입력하세요...\",key=key+\"_chat_input\"):\n",
    "        # 사용자 메시지 추가\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        \n",
    "        # 사용자 메시지 표시\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(query)\n",
    "        \n",
    "        try:                \n",
    "            if option == 'gpt-3.5-turbo(유료)' :\n",
    "                check_point = 1\n",
    "\n",
    "                # OpenAI 클라이언트 설정\n",
    "                client = openai.OpenAI(api_key=os.getenv(\"OPEN_AI_KEY\"))\n",
    "                \n",
    "                with st.spinner(\"메시지를 생성하는 중입니다...\"):\n",
    "                    # 채팅 완료 요청\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=\"gpt-3.5-turbo\",\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"당신은 도움이 되는 AI 어시스턴트입니다.\"},\n",
    "                            *st.session_state.messages\n",
    "                        ],\n",
    "                        max_tokens=1000,\n",
    "                        temperature=0.7\n",
    "                    )\n",
    "                \n",
    "                response = response.choices[0].message.content\n",
    "\n",
    "            elif option == 'upstage(유료)':\n",
    "                check_point = 2\n",
    "                \n",
    "                client = openai.OpenAI(api_key=os.getenv(\"UPSTAGE_API_KEY\") ,base_url=\"https://api.upstage.ai/v1\")\n",
    "                \n",
    "                with st.spinner(\"메시지를 생성하는 중입니다...\"):\n",
    "                    \n",
    "                    # 유사도검색 \n",
    "                    retrieved_data = database.similarity_search(query, k=3)  # k는 유사도 검색으로 가져올 문서의 개수\n",
    "                    # 질의 \n",
    "                    response = client.chat.completions.create(\n",
    "                        model=\"solar-pro2\",\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": \"당신은 도움이 되는 AI 어시스턴트입니다.\"},\n",
    "                            *gpt_data,\n",
    "                            *st.session_state.messages\n",
    "                        ],\n",
    "                        stream=False,\n",
    "                    )\n",
    "                \n",
    "                response = response.choices[0].message.content\n",
    "\n",
    "            # 추후 더 나는 로컬 llm  으로 개선 (속도 너무 느림)\n",
    "            # elif option == 'exaone3.5(무료)':\n",
    "            #     check_point = 3\n",
    "            #     with st.spinner(\"메시지를 생성하는 중입니다...\"):\n",
    "            #         llm = ChatOllama(model ='exaone3.5:2.4b', verbose=True)                    \n",
    "            #         chat_prompt_template = ChatPromptTemplate.from_messages([\n",
    "            #             (\"system\",\"당신은 사용자의 질문에 답해주는 친절한 도우미야. 당신은 다음의 정보들을 알고 있어. 화면을 찾는 질문을 받으면 이 정보를 바탕으로 사용자의 질문에 답해줘.\" + app_explain + menu_explain),\n",
    "            #             (\"human\", \"{question} 3문장 이내로 대답해줘\")\n",
    "            #         ]\n",
    "            #         )                    \n",
    "            #         menu_chain ={\"question\" : RunnablePassthrough()} |chat_prompt_template | llm | StrOutputParser()\n",
    "            #         response = menu_chain.invoke(query)\n",
    "\n",
    "        except Exception as e:\n",
    "            if check_point == 1:\n",
    "                response = f\"❌ API 오류가 발생했습니다: {str(e)}\"\n",
    "            elif check_point == 2:\n",
    "                response =f\"❌ API 오류가 발생했습니다: {str(e)}\"\n",
    "\n",
    "\n",
    "        # 봇 응답 표시\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            st.write(response)        \n",
    "        # 봇 응답 추가\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "    def clear_chat():\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "\n",
    "    if st.session_state.messages:\n",
    "        st.button(\"채팅 초기화\", on_click=clear_chat,key=key+\"_chat_clear_btn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12086f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHI\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
